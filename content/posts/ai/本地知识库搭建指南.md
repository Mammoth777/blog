---
title: "本地知识库搭建指南"
date: 2025-03-24
categories: ["AI", "工具", "Docker"]
draft: false
---

非常简单的知识库搭建方法，只要有 Docker 就行。

> 参考：[Open WebUI 文档](https://openwebui-doc-zh.pages.dev/getting-started/api-endpoints)

## 快速创建本地知识库问答

### 1. 启动 Open WebUI

官网指定命令：

```bash
docker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:main
```

实际使用的命令（推荐）：

```bash
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
```

启动后，通过 [http://localhost:3000](http://localhost:3000/) 访问 Open WebUI。

### 2. 注册登录

没啥说的，注册登录即可。

### 3. 配置模型

1. 新建一个工作空间
2. 点击工作空间，可看到模型的配置界面。点击右侧加号，可增加一个模型
3. 选择一个**基础模型**
4. 选择一个**知识库**
5. 点击最下面的保存并更新

至此，配置完毕。

#### 3.1 配置基础模型

配置路径：

1. 点击左下角管理员头像 → 显示设置弹框
2. 点击管理员设置 → 进入**管理员设置界面**
3. 点击外部连接
4. 点击管理 OpenAI API 连接

我这里配置的是硅基流动的 api：

```yaml
URL: https://api.siliconflow.cn/v1
密钥：在硅基流动管理界面可获得
模型 ID: 即模型名称，复制进输入框，点击加号即可
```

或者是阿里云的 api，我感觉这个更好用：

```yaml
URL: https://dashscope.aliyuncs.com/compatible-mode/v1
密钥：在阿里云管理界面获得
模型 ID: 复制进输入框
```

#### 3.2 配置知识库

配置路径：

1. 点击工作空间
2. 点击知识库
3. 点击右侧加号
4. 按照提示配置即可

### 4. 开启对话

开启一个新对话，左上角选择我们刚刚配置的模型即可。

### 5. 对接外部知识库

在启动容器的时候，如果指定了 `ENV=dev`，就可以在 `http://localhost:3000/docs` 看到接口文档。

然后做个定时任务，自动从外部知识库捞文档，存到这里。

## 模型选型

目前我的嵌入模型使用的是 `nomic-embed-text`，通过 `ollama` 拉取。

LLM 使用的是 `qwq-plus`，来自阿里云。

## Q&A

**Q: 连不上 `ollama` 咋办？（ollama 在宿主机）**

A: 在管理员设置 → 外部连接中，配置 ollama 地址为：`http://host.docker.internal:11434`

**Q: 不能调用 API 怎么办？**

A: 检查 baseurl，后面不要以 `/` 结尾。

## 知识库文档要求

1. mrdoc 里不同层级，尽量不要有重名文档，导出会覆盖
2. 对图片做标注
